# ğŸš€ Universal DataLoader

**AI-Powered Knowledge Graph Construction for Any Domain**

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-green.svg)](https://python.langchain.com/)
[![Neo4j](https://img.shields.io/badge/Neo4j-5.0+-red.svg)](https://neo4j.com/)

Transform unstructured data from **any domain** into rich knowledge graphs using **LangChain** and **Neo4j**. Works with servers, applications, documents, network devices, security data, and more!

## âœ¨ Universal & Domain-Agnostic

Works with **any data domain**:
- ğŸ–¥ï¸ **IT Infrastructure** (servers, networks, applications)
- ğŸ“Š **Business Systems** (processes, organizations, users)  
- ğŸ“š **Document Analysis** (manuals, reports, logs)
- ğŸ”’ **Security Data** (incidents, vulnerabilities, compliance)
- ğŸ­ **Industrial Systems** (IoT, manufacturing, monitoring)
- ğŸ¥ **Healthcare** (systems, processes, documentation)
- ğŸ’° **Financial** (transactions, systems, compliance)

## â­ Key Features

- ğŸ¤– **LangChain-Powered AI**: Uses `LLMGraphTransformer` for reliable entity extraction
- ğŸ—„ï¸ **Direct Neo4j Integration**: Automatic schema creation and data loading
- ğŸ”§ **Configuration-Driven**: YAML-based configuration for easy customization
- ğŸŒ **Domain-Agnostic**: Works with any data type - not limited to specific domains
- ğŸ“ **Flexible Data Sources**: Filesystem, APIs, databases (easily extensible)
- ğŸ—ï¸ **4-Phase Pipeline**: Raw ingestion â†’ Text processing â†’ AI extraction â†’ Graph loading
- ğŸ”’ **Production-Ready**: Environment-aware configuration and error handling
- ğŸš€ **Easy Integration**: Simple Python API with minimal setup

## ğŸ¯ Perfect For

- **DevOps & Infrastructure**: Server configs, logs, monitoring data
- **Security Analysis**: Incident reports, vulnerability scans, compliance data  
- **Business Intelligence**: Process documentation, organizational data
- **Document Analysis**: Technical manuals, reports, knowledge bases
- **Application Monitoring**: Service dependencies, performance metrics
- **Research & Analysis**: Any unstructured text data requiring graph representation

## ğŸ—ï¸ 4-Phase AI Pipeline

1. **ğŸ“ Phase 1: Raw Data Ingestion** (No AI)
2. **âš™ï¸ Phase 2: Text Processing** (Minimal AI) 
3. **ğŸ§  Phase 3: AI Entity Extraction** (LangChain LLMGraphTransformer)
4. **ğŸ—„ï¸ Phase 4: Graph Loading** (Direct Neo4j integration)

## ğŸ“‚ Directory Structure

```
universal-dataloader/
â”œâ”€â”€ core/                   # ğŸ¯ Core functionality
â”‚   â”œâ”€â”€ unified_dataloader.py    # Universal dataloader (LangChain-based)
â”‚   â”œâ”€â”€ data_models.py           # Generic data models for any domain
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config/                 # âš™ï¸ Configuration management  
â”‚   â”œâ”€â”€ config_loader.py         # Configuration loader
â”‚   â”œâ”€â”€ universal_dataloader_config.yaml  # Main configuration file
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/                  # âœ… Comprehensive test suite
â”‚   â”œâ”€â”€ test_universal_loader.py
â”‚   â”œâ”€â”€ test_langchain_approach.py
â”‚   â””â”€â”€ test_*.py
â”œâ”€â”€ examples/               # ğŸ“– Usage examples
â”‚   â””â”€â”€ example_usage.py
â”œâ”€â”€ utils/                  # ğŸ› ï¸ Utilities
â”‚   â””â”€â”€ cleanup_*.py
â”œâ”€â”€ sample_data/            # ğŸ“ Sample data for testing
â”‚   â””â”€â”€ example_system/
â”œâ”€â”€ requirements.txt        # ğŸ“¦ Dependencies
â”œâ”€â”€ setup.py               # ğŸ“¦ Package setup
â”œâ”€â”€ .env.example           # âš™ï¸ Environment template
â””â”€â”€ README.md              # ğŸ“š This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/rrbanda/dataloader.git
cd dataloader

# Install dependencies
pip install -r requirements.txt

# For full features (optional)
pip install -r requirements.txt[full]
```

### 2. Configuration

```bash
# Copy and configure environment variables
cp .env.example .env
# Edit .env with your LLM API key and Neo4j credentials

# The default configuration works out of the box with sample data
# Customize config/universal_dataloader_config.yaml as needed
```

### 3. Run with Sample Data

```python
from core.unified_dataloader import get_universal_loader

# Initialize and run with sample data
loader = get_universal_loader('development')
systems, events = loader.load_all_systems()
loader.close()

print(f"Loaded {len(systems)} systems and {len(events)} events into Neo4j!")
```

## ğŸ”§ Configuration

### Environment Variables (`.env`)
```bash
# LLM Configuration
OPENAI_BASE_URL=https://your-llm-endpoint.com/v1
OPENAI_API_KEY=your-api-key
MODEL=gpt-3.5-turbo

# Neo4j Configuration  
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=knowledge_graph
```

### Main Configuration (`config/universal_dataloader_config.yaml`)

The configuration is structured for maximum flexibility:

```yaml
# Data Sources - easily point to your data
data_sources:
  primary_data:
    type: "filesystem"
    base_path: "your_data_directory"
    file_patterns:
      logs: ["**/*.log", "**/*.txt"]
      configs: ["**/*.yaml", "**/*.json", "**/*.conf"]
      documents: ["**/*.md", "**/*.pdf"]

# Entity Extraction - customize for your domain
entity_extraction:
  target_entities:
    - "System"      # Servers, applications, devices
    - "Service"     # Running processes, APIs  
    - "Event"       # Incidents, changes, alerts
    - "Document"    # Files, logs, reports
    # Add your domain-specific entities
    
  target_relationships:
    - "RUNS"        # System RUNS Service
    - "GENERATES"   # System GENERATES Event
    - "CONTAINS"    # System CONTAINS Component
    # Add your domain-specific relationships
```

## ğŸ’¼ Real-World Examples

### Example 1: IT Infrastructure Analysis
```python
# Point to your server configs and logs
config = {
    "data_sources": {
        "servers": {
            "base_path": "/var/log/servers",
            "file_patterns": {
                "configs": ["**/*.conf", "**/*.yaml"],
                "logs": ["**/*.log"]
            }
        }
    }
}

loader = get_universal_loader('production')
# Extracts: Server nodes, Service relationships, Configuration entities
```

### Example 2: Security Incident Analysis  
```python
# Point to security logs and incident reports
config = {
    "data_sources": {
        "security": {
            "base_path": "/security/incidents",
            "file_patterns": {
                "incidents": ["**/*incident*.txt", "**/*alert*.log"],
                "reports": ["**/*.pdf", "**/*.md"]
            }
        }
    }
}

# Extracts: Incident events, Affected systems, User entities, Security relationships
```

### Example 3: Business Process Documentation
```python
# Point to business documents and process files  
config = {
    "data_sources": {
        "business": {
            "base_path": "/business/processes",
            "file_patterns": {
                "processes": ["**/*process*.md", "**/*workflow*.yaml"],
                "documents": ["**/*.pdf", "**/*.docx"]
            }
        }
    }
}

# Extracts: Process entities, Role relationships, Document references
```

## ğŸ› ï¸ Development & Extension

### Adding Custom Entity Types
```python
# In your configuration
entity_extraction:
  target_entities:
    - "CustomEntity"     # Your specific entity type
    - "DomainSpecific"   # Another custom entity
    
  target_relationships:
    - ("CustomEntity", "RELATES_TO", "System")
    - ("DomainSpecific", "CONTAINS", "CustomEntity")
```

### Creating New Data Source Adapters
```python
class CustomDataSourceAdapter(DataSourceAdapter):
    def list_available_systems(self) -> List[str]:
        # Your custom logic to discover data sources
        pass
        
    def load_system_files(self, system_id: str) -> Dict[str, str]:
        # Your custom logic to load data
        pass
```

### Running Tests
```bash
# Run all tests
python -m pytest tests/ -v

# Test specific components
python tests/test_universal_loader.py
python tests/test_langchain_approach.py
```

## ğŸš€ Production Deployment

### Docker Deployment
```bash
# Build the image
docker build -t universal-dataloader .

# Run with environment variables
docker run -e OPENAI_API_KEY=your-key \
           -e NEO4J_URI=bolt://neo4j:7687 \
           -v /your/data:/app/data \
           universal-dataloader
```

### Environment-Specific Configuration
```yaml
# Development environment
environments:
  development:
    neo4j_config:
      management:
        clear_on_startup: true    # Clean slate for development
        
# Production environment
environments:
  production:
    neo4j_config:
      management:
        clear_on_startup: false   # Preserve data in production
        backup_before_clear: true
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Areas for Contribution
- ğŸ”Œ **New Data Source Adapters** (APIs, databases, cloud storage)
- ğŸ¯ **Domain-Specific Entity Templates** (healthcare, finance, manufacturing)
- ğŸ§ª **Testing & Validation** (more test cases, data validation)
- ğŸ“š **Documentation** (tutorials, examples, best practices)
- âš¡ **Performance Optimizations** (parallel processing, caching)

## ğŸ“š Documentation

- ğŸ“– **[Configuration Guide](config/universal_dataloader_config.yaml)** - Complete configuration reference
- ğŸš€ **[Examples](examples/)** - Real-world usage patterns
- ğŸ§ª **[Testing](tests/)** - Comprehensive test suite
- ğŸ”§ **[Setup Guide](.env.example)** - Environment configuration

## ğŸ†˜ Support & Community

- ğŸ› **[Issues](https://github.com/rrbanda/dataloader/issues)** - Bug reports and feature requests
- ğŸ’¬ **[Discussions](https://github.com/rrbanda/dataloader/discussions)** - Community support and ideas
- ğŸ“§ **Contact** - your.email@example.com for direct support

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built with these amazing open-source projects:
- **[LangChain](https://python.langchain.com/)** - LLM application framework
- **[Neo4j](https://neo4j.com/)** - Graph database platform  
- **[OpenAI](https://openai.com/)** - AI models and APIs

---

**ğŸŒŸ Star this project if it helps you build better knowledge graphs! ğŸŒŸ**